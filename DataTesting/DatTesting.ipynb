{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m G\u001b[38;5;241m.\u001b[39madd_edges_from(edges_list)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Perform community detection using the Louvain method\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m partition \u001b[38;5;241m=\u001b[39m \u001b[43mcommunity_louvain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Get a list of unique communities and their sizes\u001b[39;00m\n\u001b[0;32m     45\u001b[0m communities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(partition\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\zindani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\community\\community_louvain.py:249\u001b[0m, in \u001b[0;36mbest_partition\u001b[1;34m(graph, partition, weight, resolution, randomize, random_state)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbest_partition\u001b[39m(graph,\n\u001b[0;32m    164\u001b[0m                    partition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    165\u001b[0m                    weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    166\u001b[0m                    resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m,\n\u001b[0;32m    167\u001b[0m                    randomize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    168\u001b[0m                    random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the partition of the graph nodes which maximises the modularity\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m    (or try..) using the Louvain heuristices\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    >>> plt.show()\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     dendo \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_dendrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mrandomize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m partition_at_level(dendo, \u001b[38;5;28mlen\u001b[39m(dendo) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zindani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\community\\community_louvain.py:352\u001b[0m, in \u001b[0;36mgenerate_dendrogram\u001b[1;34m(graph, part_init, weight, resolution, randomize, random_state)\u001b[0m\n\u001b[0;32m    350\u001b[0m status\u001b[38;5;241m.\u001b[39minit(current_graph, weight, part_init)\n\u001b[0;32m    351\u001b[0m status_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m--> 352\u001b[0m \u001b[43m__one_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m new_mod \u001b[38;5;241m=\u001b[39m __modularity(status, resolution)\n\u001b[0;32m    354\u001b[0m partition \u001b[38;5;241m=\u001b[39m __renumber(status\u001b[38;5;241m.\u001b[39mnode2com)\n",
      "File \u001b[1;32mc:\\Users\\zindani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\community\\community_louvain.py:486\u001b[0m, in \u001b[0;36m__one_level\u001b[1;34m(graph, status, weight_key, resolution, random_state)\u001b[0m\n\u001b[0;32m    484\u001b[0m com_node \u001b[38;5;241m=\u001b[39m status\u001b[38;5;241m.\u001b[39mnode2com[node]\n\u001b[0;32m    485\u001b[0m degc_totw \u001b[38;5;241m=\u001b[39m status\u001b[38;5;241m.\u001b[39mgdegrees\u001b[38;5;241m.\u001b[39mget(node, \u001b[38;5;241m0.\u001b[39m) \u001b[38;5;241m/\u001b[39m (status\u001b[38;5;241m.\u001b[39mtotal_weight \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.\u001b[39m)  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m neigh_communities \u001b[38;5;241m=\u001b[39m \u001b[43m__neighcom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m remove_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m neigh_communities\u001b[38;5;241m.\u001b[39mget(com_node,\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m    488\u001b[0m     resolution \u001b[38;5;241m*\u001b[39m (status\u001b[38;5;241m.\u001b[39mdegrees\u001b[38;5;241m.\u001b[39mget(com_node, \u001b[38;5;241m0.\u001b[39m) \u001b[38;5;241m-\u001b[39m status\u001b[38;5;241m.\u001b[39mgdegrees\u001b[38;5;241m.\u001b[39mget(node, \u001b[38;5;241m0.\u001b[39m)) \u001b[38;5;241m*\u001b[39m degc_totw\n\u001b[0;32m    489\u001b[0m __remove(node, com_node,\n\u001b[0;32m    490\u001b[0m          neigh_communities\u001b[38;5;241m.\u001b[39mget(com_node, \u001b[38;5;241m0.\u001b[39m), status)\n",
      "File \u001b[1;32mc:\\Users\\zindani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\community\\community_louvain.py:518\u001b[0m, in \u001b[0;36m__neighcom\u001b[1;34m(node, graph, status, weight_key)\u001b[0m\n\u001b[0;32m    516\u001b[0m         edge_weight \u001b[38;5;241m=\u001b[39m datas\u001b[38;5;241m.\u001b[39mget(weight_key, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    517\u001b[0m         neighborcom \u001b[38;5;241m=\u001b[39m status\u001b[38;5;241m.\u001b[39mnode2com[neighbor]\n\u001b[1;32m--> 518\u001b[0m         weights[neighborcom] \u001b[38;5;241m=\u001b[39m \u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighborcom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m edge_weight\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community.community_louvain as community_louvain\n",
    "\n",
    "# Load the streamer data\n",
    "twitchDf = pd.read_csv('large_twitch_features.csv')\n",
    "\n",
    "# Remove rows where the language is \"OTHER\" or dead_account is 1\n",
    "twitchDf = twitchDf[(twitchDf['language'] != 'OTHER') & (twitchDf['dead_account'] != 1)]\n",
    "\n",
    "# Drop the 'updated_at' column\n",
    "twitchDf = twitchDf.drop(columns=['updated_at'], errors='ignore')\n",
    "\n",
    "# Load the friendships data\n",
    "edges = pd.read_csv('large_twitch_edges.csv')\n",
    "\n",
    "# Ensure the 'created_at' column is in datetime format\n",
    "twitchDf['created_at'] = pd.to_datetime(twitchDf['created_at'])\n",
    "\n",
    "# Filter rows for the years 2007 to 2009\n",
    "twitchDf_2007_2009 = twitchDf[(twitchDf['created_at'].dt.year >= 2007) & (twitchDf['created_at'].dt.year <= 2014)]\n",
    "\n",
    "# Extract the 'numeric_id' values from the filtered DataFrame\n",
    "numeric_ids_2007_2009 = twitchDf_2007_2009['numeric_id'].unique()\n",
    "\n",
    "# Filter the friendships DataFrame to include only rows where both numeric_id_1 and numeric_id_2 are in numeric_ids_2007_2009\n",
    "filtered_edges = edges[\n",
    "  (edges['numeric_id_1'].isin(numeric_ids_2007_2009)) & \n",
    "  (edges['numeric_id_2'].isin(numeric_ids_2007_2009))\n",
    "]\n",
    "\n",
    "# Create a NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges to the graph\n",
    "edges_list = list(zip(filtered_edges['numeric_id_1'], filtered_edges['numeric_id_2']))\n",
    "G.add_edges_from(edges_list)\n",
    "\n",
    "# Perform community detection using the Louvain method\n",
    "partition = community_louvain.best_partition(G)\n",
    "\n",
    "# Get a list of unique communities and their sizes\n",
    "communities = set(partition.values())\n",
    "community_sizes = {community: sum(1 for node in partition.values() if node == community) for community in communities}\n",
    "\n",
    "# Define a list of colors\n",
    "color_names = ['red', 'blue', 'green', 'purple', 'orange', 'pink', 'brown', 'grey', 'olive', 'cyan', 'black', 'yellow']\n",
    "color_map = {community: color_names[i % len(color_names)] for i, community in enumerate(communities)}\n",
    "\n",
    "# Assign colors to nodes based on their community\n",
    "node_colors = [color_map[partition[node]] for node in G.nodes()]\n",
    "\n",
    "# Get language labels for nodes\n",
    "language_map = twitchDf.set_index('numeric_id')['language'].to_dict()\n",
    "\n",
    "# Layout for organized communities with minimal overlap (using Spring Layout)\n",
    "pos = nx.spring_layout(G, k=0.4)  # Adjust k for node spacing (lower k for tighter layout)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Draw nodes with community colors and reduce node size\n",
    "nx.draw_networkx_nodes(G, pos, node_size=150, node_color=node_colors, alpha=0.8)\n",
    "\n",
    "# Draw edges with reduced opacity\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
    "\n",
    "# Draw labels inside the nodes with the language\n",
    "labels = {node: language_map.get(node, '') for node in G.nodes()}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=10, font_color='black')\n",
    "\n",
    "# Show plot\n",
    "plt.title('Twitch Network Communities (2007-2009)', fontsize=20)\n",
    "plt.axis('off')  # Remove unnecessary axes\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()\n",
    "\n",
    "# Calculate total views per community and views per size\n",
    "community_views = {}\n",
    "community_views_per_size = {}\n",
    "\n",
    "# Initialize reordered_community_views dictionary\n",
    "reordered_community_views = {}\n",
    "\n",
    "# First, sort communities by size in descending order and create a new order\n",
    "sorted_communities_by_size = sorted(community_sizes.items(), key=lambda x: x[1], reverse=True)\n",
    "community_order = {community: i for i, (community, _) in enumerate(sorted_communities_by_size)}\n",
    "\n",
    "# Reassign community numbers based on the new order\n",
    "reordered_partition = {node: community_order[partition[node]] for node in partition}\n",
    "reordered_communities = set(reordered_partition.values())\n",
    "reordered_community_sizes = {community: sum(1 for node in reordered_partition.values() if node == community) for community in reordered_communities}\n",
    "\n",
    "# Calculate total views and views per size for reordered communities\n",
    "max_views_per_size = 0\n",
    "for community in reordered_communities:\n",
    "    community_nodes = [node for node in G.nodes() if reordered_partition[node] == community]\n",
    "    community_df = twitchDf[twitchDf['numeric_id'].isin(community_nodes)]\n",
    "    total_views = community_df['views'].sum()\n",
    "    reordered_community_views[community] = total_views\n",
    "    views_per_size = total_views / reordered_community_sizes[community]\n",
    "    community_views_per_size[community] = views_per_size\n",
    "    if views_per_size > max_views_per_size:\n",
    "        max_views_per_size = views_per_size\n",
    "\n",
    "# Normalize the views per size to be between 1 and 100\n",
    "for community in reordered_communities:\n",
    "    community_views_per_size[community] = (community_views_per_size[community] / max_views_per_size) * 100\n",
    "\n",
    "# Calculate centrality metrics\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# Print summary of community features\n",
    "summary_lines = []\n",
    "for community in sorted_communities_by_size:\n",
    "    community_index = community_order[community[0]]\n",
    "    community_nodes = [node for node in G.nodes() if reordered_partition[node] == community_index]\n",
    "    community_df = twitchDf[twitchDf['numeric_id'].isin(community_nodes)]\n",
    "    \n",
    "    community_size = reordered_community_sizes[community_index]\n",
    "    languages = community_df['language'].value_counts().to_dict()\n",
    "    affiliates = community_df['affiliate'].sum()\n",
    "    mature = community_df['mature'].sum()\n",
    "    views = reordered_community_views[community_index]\n",
    "    average_lifetime = community_df['life_time'].mean()\n",
    "    dead_accounts = community_df['dead_account'].sum()\n",
    "    views_per_size = community_views_per_size[community_index]\n",
    "    \n",
    "    # Calculate additional community metrics\n",
    "    density = nx.density(G.subgraph(community_nodes))\n",
    "    average_degree = sum(dict(G.degree(community_nodes)).values()) / len(community_nodes)\n",
    "    \n",
    "    # Calculate size to mature and affiliate aspects\n",
    "    mature_ratio = (mature / community_size) if mature != 0 else community_size\n",
    "    affiliate_ratio = (affiliates / community_size) if affiliates != 0 else community_size\n",
    "    \n",
    "    # Calculate average centralities for the community\n",
    "    avg_betweenness_centrality = sum(betweenness_centrality[node] for node in community_nodes) / len(community_nodes)\n",
    "    avg_degree_centrality = sum(degree_centrality[node] for node in community_nodes) / len(community_nodes)\n",
    "    avg_closeness_centrality = sum(closeness_centrality[node] for node in community_nodes) / len(community_nodes)\n",
    "    \n",
    "    # Top 5 users by centrality metrics\n",
    "    top_users = community_df[['numeric_id', 'views', 'life_time', 'affiliate', 'mature', 'language']].copy()\n",
    "    top_users['betweenness_centrality'] = top_users['numeric_id'].map(betweenness_centrality)\n",
    "    top_users['degree_centrality'] = top_users['numeric_id'].map(degree_centrality)\n",
    "    top_users['closeness_centrality'] = top_users['numeric_id'].map(closeness_centrality)\n",
    "    \n",
    "    top_users = top_users.sort_values(\n",
    "        by=['betweenness_centrality', 'degree_centrality', 'closeness_centrality'],\n",
    "        ascending=False\n",
    "    ).head(5)\n",
    "    \n",
    "    top_users_summary = \"\\n\".join(\n",
    "        f\"User {row['numeric_id']}:\\n\"\n",
    "        f\"  Betweenness Centrality: {row['betweenness_centrality']:.4f}\\n\"\n",
    "        f\"  Degree Centrality: {row['degree_centrality']:.4f}\\n\"\n",
    "        f\"  Closeness Centrality: {row['closeness_centrality']:.4f}\\n\"\n",
    "        f\"  Views: {row['views']}\\n\"\n",
    "        f\"  Affiliate: {row['affiliate']}\\n\"\n",
    "        f\"  Mature Content: {row['mature']}\\n\"\n",
    "        f\"  Language: {row['language']}\\n\"\n",
    "        f\"  Lifetime: {row['life_time']}\\n\"\n",
    "        for _, row in top_users.iterrows()\n",
    "    )\n",
    "\n",
    "    community_color = color_map[community_index]\n",
    "    summary_lines.append(\n",
    "        f\"Community {community_index} (Color: {community_color}):\\n\"\n",
    "        f\"Size: {community_size}\\n\"\n",
    "        f\"Views per Size: {views_per_size:.2f}\\n\"\n",
    "        f\"Size to Mature Aspect: {mature_ratio:.2f}\\n\"\n",
    "        f\"Size to Affiliate Aspect: {affiliate_ratio:.2f}\\n\"\n",
    "        f\"Density: {density:.2f}\\n\"\n",
    "        f\"Average Degree: {average_degree:.2f}\\n\"\n",
    "        f\"Languages: {len(languages)} {languages}\\n\"\n",
    "        f\"Affiliates: {affiliates}\\n\"\n",
    "        f\"Mature: {mature}\\n\"\n",
    "        f\"Views: {views}\\n\"\n",
    "        f\"Average Life Time: {average_lifetime:.2f}\\n\"\n",
    "        f\"Average Betweenness Centrality: {avg_betweenness_centrality:.4f}\\n\"\n",
    "        f\"Average Degree Centrality: {avg_degree_centrality:.4f}\\n\"\n",
    "        f\"Average Closeness Centrality: {avg_closeness_centrality:.4f}\\n\"\n",
    "        f\"\\nTop 5 Users:\\n{top_users_summary}\\n\"\n",
    "        f\"{'-'*20}\\n\"\n",
    "    )\n",
    "\n",
    "# Print the summary\n",
    "for line in summary_lines:\n",
    "    print(line)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
